{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from numpy.random import rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################\n",
    "## Constants from global.m\n",
    "\n",
    "# number of training iterations\n",
    "# (was: 5)\n",
    "T = 10\n",
    "\n",
    "# learning rate\n",
    "# (was: 0.00005)\n",
    "e = 0.005\n",
    "\n",
    "# regularization constant\n",
    "LAMBDA = 0.01\n",
    "\n",
    "# number of cores for parallel processing (unused)\n",
    "# global CORES = 16\n",
    "\n",
    "# range of values for initialization of weights\n",
    "INIT_VAR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arg_list = argv ();\n",
    "#training_file = arg_list{1, 1};\n",
    "#model_file = arg_list{2, 1};\n",
    "\n",
    "training_file = \"sample/small_training_data.csv\"\n",
    "model_file = \"/tmp/model-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data...\n",
      "training data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#% load constants (done above)\n",
    "#addpath(\".\")\n",
    "#source \"./global.m\";\n",
    "\n",
    "#% load training dataset\n",
    "print('loading training data...')\n",
    "\n",
    "#data = load(training_file);\n",
    "#list_id = data(:, 1);\n",
    "#X = data(:, 2:size(data, 2)-1);\n",
    "#y = data(:, size(data, 2));\n",
    "\n",
    "data = pd.read_csv(training_file, sep=',',header=None)\n",
    "list_id = data.iloc[:,0]\n",
    "X = data.iloc[:, 2:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "print('training data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topp(v):\n",
    "    return np.exp(v)/sum(np.exp(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNN(list_id, X, y, T, e, quiet=False):\n",
    "    #% load constants\n",
    "    #source global.m;\n",
    "    global INIT_VAR\n",
    "    global LAMBDA\n",
    "    \n",
    "    #m = size(X,1);\n",
    "    #n_features = size(X,2);\n",
    "    #n_lists = size(unique(list_id),1);\n",
    "\n",
    "    m = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "    n_lists = len(set(list_id))\n",
    "    \n",
    "    #% linear neural network parameter initialization\n",
    "    #omega = rand(n_features,1)*INIT_VAR;\n",
    "    \n",
    "    omega = rand(n_features,1)*INIT_VAR;\n",
    "    \n",
    "    #for t = 1:T\n",
    "    for t in range(1,T):\n",
    "    \n",
    "    #    fprintf(\"iteration %d: \", t)\n",
    "        print(\"iteration %d\" % t)\n",
    "\n",
    "    #    % forward propagation\n",
    "    #    z =  X * omega;\n",
    "        \n",
    "        z = np.matmul(X, omega)\n",
    "\n",
    "    #    % cost\n",
    "    #    fprintf(\"computing cost... \")\n",
    "    \n",
    "        print(\"computing cost... \")\n",
    "\n",
    "    #    % with regularization\n",
    "    #    J = listwise_cost(y,z, list_id) + ((z.*z)'.*LAMBDA);\n",
    "    #    % without regularization\n",
    "    #    %J = listwise_cost(y,z, list_id);\n",
    "    \n",
    "        J_listwise_cost = listwise_cost(y, z, list_id)\n",
    "        J_regularizer_cost = np.multiply(z, z) * LAMBDA\n",
    "        J = np.sum(J_listwise_cost) + np.sum(J_regularizer_cost)\n",
    "        \n",
    "        print(\"cost_listwise = %f, cost_regularizer = %f, total_cost = %f\" % (np.sum(J_listwise_cost), np.sum(J_regularizer_cost), np.sum(J)))\n",
    "\n",
    "    #    fprintf(\"computing gradient...\")\n",
    "    #    grad = listnet_gradient(X, y, z, list_id);\n",
    "    \n",
    "        print(\"IMPLEMENT ME - gradient\")\n",
    "    \n",
    "    #    % parameter update\n",
    "    #    omega = omega - (e .* sum(grad',2));\n",
    "    \n",
    "        print(\"IMPLEMENT ME - omega update\")\n",
    "\n",
    "    # Return value\n",
    "    return omega\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listwise_cost(y, z, list_id):\n",
    "    #ly = @(i) y(find(list_id == list_id(i)),:);\n",
    "    ly = lambda i: y[list_id == i]\n",
    "    \n",
    "    #lz = @(i) z(find(list_id == list_id(i)),:);\n",
    "    lz = lambda i: z[list_id == i]\n",
    "\n",
    "    #j = @(i) (-sum(topp(ly(i)) .* log( topp(lz(i)) )));\n",
    "    #J = pararrayfun(CORES, j,1:size(z,1), \"VerboseLevel\", 0);\n",
    "    j = lambda i: -np.dot( topp(ly(i)).as_matrix(), np.log(topp(lz(i))) )\n",
    "    \n",
    "    J = list()\n",
    "    for i in range(0, len(set(list_id))):\n",
    "        ndocs = len(ly(i))\n",
    "        #print(\"Query %d ndocs %d\" % (i, ndocs))\n",
    "        for k in range(0, ndocs):\n",
    "            J.append(np.asscalar(j(i)))\n",
    "        \n",
    "\n",
    "    for val in (1, 2, 10, 16, 17):\n",
    "        print(\"listwise_cost[%d] = %f\" % (val, J[val-1]))\n",
    "    print(\"len(listwise_cost)=%d\" % len(J))\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training, 10 iteration, 6503 examples, learning rate 0.005000...\n",
      "iteration 1\n",
      "computing cost... \n",
      "listwise_cost[1] = 1.931813\n",
      "listwise_cost[2] = 1.931813\n",
      "listwise_cost[10] = 1.925092\n",
      "listwise_cost[16] = 1.100396\n",
      "listwise_cost[17] = 1.100396\n",
      "len(listwise_cost)=6503\n",
      "cost_listwise = 12599.044118, cost_regularizer = 0.189348, total_cost = 12599.233466\n",
      "IMPLEMENT ME - gradient\n",
      "IMPLEMENT ME - omega update\n",
      "iteration 2\n",
      "computing cost... \n",
      "listwise_cost[1] = 1.931813\n",
      "listwise_cost[2] = 1.931813\n",
      "listwise_cost[10] = 1.925092\n",
      "listwise_cost[16] = 1.100396\n",
      "listwise_cost[17] = 1.100396\n",
      "len(listwise_cost)=6503\n",
      "cost_listwise = 12599.044118, cost_regularizer = 0.189348, total_cost = 12599.233466\n",
      "IMPLEMENT ME - gradient\n",
      "IMPLEMENT ME - omega update\n",
      "iteration 3\n",
      "computing cost... \n",
      "listwise_cost[1] = 1.931813\n",
      "listwise_cost[2] = 1.931813\n",
      "listwise_cost[10] = 1.925092\n",
      "listwise_cost[16] = 1.100396\n",
      "listwise_cost[17] = 1.100396\n",
      "len(listwise_cost)=6503\n",
      "cost_listwise = 12599.044118, cost_regularizer = 0.189348, total_cost = 12599.233466\n",
      "IMPLEMENT ME - gradient\n",
      "IMPLEMENT ME - omega update\n",
      "iteration 4\n",
      "computing cost... \n"
     ]
    }
   ],
   "source": [
    "print('training, %d iteration, %d examples, learning rate %f...' % (T, X.shape[0], e))\n",
    "omega = trainNN(list_id, X, y, T, e);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPLEMENT ME: save omega to model_file\n"
     ]
    }
   ],
   "source": [
    "#save(model_file, \"omega\");\n",
    "print(\"IMPLEMENT ME: save omega to model_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
